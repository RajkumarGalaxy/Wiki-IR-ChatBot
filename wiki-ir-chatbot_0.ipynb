{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Wiki-IR-ChatBot\n\n### A ChatBot that can respond to humans by retrieving information directly from Wikipedia.\n### User is open to choose any topic of interest!\n\n\n![robo_chat](https://raw.githubusercontent.com/RajkumarGalaxy/dataset/master/Images/robo_chat.jpg)\n> [Image by Brett Jordan](https://unsplash.com/@brett_jordan)\n\n### What is a chatbot?\n> A ChatBot is a kind of virtual assistant that can build conversations with human users! A Chatting Robot. Building a chatbot is one of the popular tasks in Natural Language Processing.\n\n### What is Information Retrieval?\n> Information Retrieval (or, IR in short) is the task of identifying and collecting the most relevant information from a source based on a pre-defined heuristic. Text data is a good example of unordered data while it is abudant everywhere. It is hard to find the information manually from a huge collection of text data. Since need of information is time-bound in general, a good IR system is always in need. \n\n### Are all chatbots the same?\n> Chatbots fall under three common categories:\n>##### 1. Rule-based chatbots\n>##### 2. Retrieval-based chatbots\n>##### 3. Intelligent chatbots\n\n### Rule-based chatbots\n> These bots respond to users' inputs based on certain pre-specified rules. For instance, these rules can be defined as if-elif-else statements. While writing rules for these chatbots, it is important to expect all possible user inputs, else the bot may fail to answer properly. Hence, rule-based chatbots do not possess any cognitive skills.\n\n### Retrieval-based chatbots\n> These bots respond to users' inputs by retrieving the most relevant information from the given text document. The most relevant information can be determined by Natural Language Processing with a scoring system such as cosine-similarity-score. Though these bots use NLP to do conversations, they lack cognitive skills to match a real human chatting companion. This [Wiki-IR-ChatBot](https://github.com/RajkumarGalaxy/Wiki-IR-ChatBot) falls under this category!\n\n### Intelligent AI chatbots\n> These bots respond to users' inputs after understanding the inputs, as humans do. These bots are trained with a Machine Learning Model on a large training dataset of human conversations. These bots are cognitive to match a human in conversing. Popular Virtual Assistants such as Amazon's Alexa, Apple's Siri fall under this category. Further, most of these bots can make conversations based on the preceding chat texts. [Conversational AI ChatBot](https://github.com/RajkumarGalaxy/Conversational-AI-ChatBot), built by [Author](https://github.com/RajkumarGalaxy), employs Microsoft's DialoGPT to make intelligent conversations!\n\n### In this project?\n> This project builds an information retrieval (IR) chatbot that can scrape Wikipedia using BeautifulSoup in the topic of user's interest and collect information against user's queries following a heuristic backed by TF-IDF score and cosine-similarity score. This Wiki-IR-ChatBot is user-friendly in permitting users to choose any topic and presenting either crisp and short response or detailed response. It leverages NLTK library to do text processing and scikit-learn library to do modeling. Let's dive deep!\n","metadata":{}},{"cell_type":"markdown","source":"# Create Environment by Importing Libraries","metadata":{}},{"cell_type":"code","source":"# To scrape Wikipedia\nfrom bs4 import BeautifulSoup\n# To access contents from URLs\nimport requests\n# to preprocess text\nimport nltk\n# to handle punctuations\nfrom string import punctuation\n# TF-IDF vectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n# cosine similarity score\nfrom sklearn.metrics.pairwise import cosine_similarity \n# to do array operations\nimport numpy as np\n# to have sleep option\nfrom time import sleep \n\n#nltk.download('stopwords')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-29T06:02:43.855741Z","iopub.execute_input":"2021-12-29T06:02:43.856076Z","iopub.status.idle":"2021-12-29T06:02:44.131205Z","shell.execute_reply.started":"2021-12-29T06:02:43.856045Z","shell.execute_reply":"2021-12-29T06:02:44.130173Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","output_type":"stream"},{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"markdown","source":"# Create a ChatBot Class\n\nA chatbot class that can perform information retrieval (IR) from Wikipedia, make coversations with human users based on the retrieved data!","metadata":{}},{"cell_type":"code","source":"class ChatBot():\n    \n    # initialize bot\n    def __init__(self):\n        # flag whether to end chat\n        self.end_chat = False\n        # flag whether topic is found in wikipedia\n        self.got_topic = False\n        # flag whether to call respond()\n        # in some cases, response be made already\n        self.do_not_respond = True\n        \n        # wikipedia title\n        self.title = None\n        # wikipedia scraped data as paragraphs\n        self.text_data = []\n        # data as sentences\n        self.sentences = []\n        # to keep track of paragraph indices\n        # corresponding to all sentences\n        self.para_indices = []\n        # currently retrieved sentence id\n        self.current_sent_idx = None\n        \n        # a punctuation dictionary\n        self.punctuation_dict = str.maketrans({p:None for p in punctuation})\n        # wordnet lemmatizer for preprocessing text\n        self.lemmatizer = nltk.stem.WordNetLemmatizer()\n        # collection of stopwords\n        self.stopwords = nltk.corpus.stopwords.words('english')\n        # initialize chatting\n        self.greeting()\n\n    # greeting method - to be called internally\n    # chatbot initializing chat on screen with greetings\n    def greeting(self):\n        print(\"Initializing ChatBot ...\")\n        # some time to get user ready\n        sleep(2)\n        # chat ending tags\n        print('Type \"bye\" or \"quit\" or \"exit\" to end chat')\n        sleep(2)\n        # chatbot descriptions\n        print('\\nEnter your topic of interest when prompted. \\\n        \\nChaBot will access Wikipedia, prepare itself to \\\n        \\nrespond to your queries on that topic. \\n')\n        sleep(3)\n        print('ChatBot will respond with short info. \\\n        \\nIf you input \"more\", it will give you detailed info \\\n        \\nYou can also jump to next query')\n        # give time to read what has been printed\n        sleep(3)\n        print('-'*50)\n        # Greet and introduce\n        greet = \"Hello, Great day! Please give me a topic of your interest. \"\n        print(\"ChatBot >>  \" + greet)\n        \n    # chat method - should be called by user\n    # chat method controls inputs, responses, data scraping, preprocessing, modeling.\n    # once an instance of ChatBot class is initialized, chat method should be called\n    # to do the entire chatting on one go!\n    def chat(self):\n        # continue chat\n        while not self.end_chat:\n            # receive input\n            self.receive_input()\n            # finish chat if opted by user\n            if self.end_chat:\n                print('ChatBot >>  See you soon! Bye!')\n                sleep(2)\n                print('\\nQuitting ChatBot ...')\n            # if data scraping successful\n            elif self.got_topic:\n                # in case not already responded\n                if not self.do_not_respond:\n                    self.respond()\n                # clear flag so that bot can respond next time\n                self.do_not_respond = False\n    \n    # receive_input method - to be called internally\n    # recieves input from user and makes preliminary decisions\n    def receive_input(self):\n        # receive input from user\n        text = input(\"User    >> \")\n        # end conversation if user wishes so\n        if text.lower().strip() in ['bye', 'quit', 'exit']:\n            # turn flag on \n            self.end_chat=True\n        # if user needs more information \n        elif text.lower().strip() == 'more':\n            # respond here itself\n            self.do_not_respond = True\n            # if at least one query has been received \n            if self.current_sent_idx != None:\n                response = self.text_data[self.para_indices[self.current_sent_idx]]\n            # prompt user to start querying\n            else:\n                response = \"Please input your query first!\"\n            print(\"ChatBot >> \" + response)\n        # if topic is not chosen\n        elif not self.got_topic:\n            self.scrape_wiki(text)\n        else:\n            # add user input to sentences, so that we can vectorize in whole\n            self.sentences.append(text)\n                \n    # respond method - to be called internally\n    def respond(self):\n        # tf-idf-modeling\n        vectorizer = TfidfVectorizer(tokenizer=self.preprocess)\n        # fit data and obtain tf-idf vector\n        tfidf = vectorizer.fit_transform(self.sentences)\n        # calculate cosine similarity scores\n        scores = cosine_similarity(tfidf[-1],tfidf) \n        # identify the most closest sentence\n        self.current_sent_idx = scores.argsort()[0][-2]\n        # find the corresponding score value\n        scores = scores.flatten()\n        scores.sort()\n        value = scores[-2]\n        # if there is matching sentence\n        if value != 0:\n            print(\"ChatBot >> \" + self.sentences[self.current_sent_idx]) \n        # if no sentence is matching the query\n        else:\n            print(\"ChatBot >>  I am not sure. Sorry!\" )\n        # remove the user query from sentences\n        del self.sentences[-1]\n        \n    # scrape_wiki method - to be called internally.\n    # called when user inputs topic of interest.\n    # employs requests to access Wikipedia via URL.\n    # employs BeautifulSoup to scrape paragraph tagged data\n    # and h1 tagged article heading.\n    # employs NLTK to tokenize data\n    def scrape_wiki(self,topic):\n        # process topic as required by Wikipedia URL system\n        topic = topic.lower().strip().capitalize().split(' ')\n        topic = '_'.join(topic)\n        try:\n            # creata an url\n            link = 'https://en.wikipedia.org/wiki/'+ topic\n            # access contents via url\n            data = requests.get(link).content\n            # parse data as soup object\n            soup = BeautifulSoup(data, 'html.parser')\n            # extract all paragraph data\n            # scrape strings with html tag 'p'\n            para = soup.findAll('p')\n            # iterate over all paragraphs\n            for p in para:\n                # a bucket to collect processed data\n                a = []\n                # iterate over para contents and tags\n                for i in p.contents:\n                    # exclude references, superscripts, formattings\n                    if i.name != 'sup' and i.string != None:\n                        stripped = ' '.join(i.string.strip().split())\n                        # collect data pieces\n                        a.append(stripped)\n                # with collected string pieces formulate a single string\n                # each string is a paragraph\n                self.text_data.append(' '.join(a))\n            \n            # obtain sentences from paragraphs\n            for i,para in enumerate(self.text_data):\n                sentences = nltk.sent_tokenize(para)\n                self.sentences.extend(sentences)\n                # for each sentence, its para index must be known\n                # it will be useful in case user prompts \"more\" info\n                index = [i]*len(sentences)\n                self.para_indices.extend(index)\n            \n            # extract h1 heading tag from soup object\n            self.title = soup.find('h1').string\n            # turn respective flag on\n            self.got_topic = True\n            # announce user that chatbot is ready now\n            print('ChatBot >>  Topic is \"Wikipedia: {}\". Let\\'s chat!'.format(self.title)) \n        # in case of unavailable topics\n        except Exception as e:\n            print('ChatBot >>  Error: {}. \\\n            Please input some other topic!'.format(e))\n        \n    # preprocess method - to be called internally by Tf-Idf vectorizer\n    # text preprocessing, stopword removal, lemmatization, word tokenization\n    def preprocess(self, text):\n        # remove punctuations\n        text = text.lower().strip().translate(self.punctuation_dict) \n        # tokenize into words\n        words = nltk.word_tokenize(text)\n        # remove stopwords\n        words = [w for w in words if w not in self.stopwords]\n        # lemmatize \n        return [self.lemmatizer.lemmatize(w) for w in words]\n","metadata":{"execution":{"iopub.status.busy":"2021-12-29T06:34:47.342097Z","iopub.execute_input":"2021-12-29T06:34:47.343023Z","iopub.status.idle":"2021-12-29T06:34:47.369128Z","shell.execute_reply.started":"2021-12-29T06:34:47.342983Z","shell.execute_reply":"2021-12-29T06:34:47.368179Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"# Happy Chatting!\n\nInitialize ChatBot and start chatting.","metadata":{}},{"cell_type":"code","source":"# instantiate an object\nwiki = ChatBot()\n# call chat method\nwiki.chat()","metadata":{"execution":{"iopub.status.busy":"2021-12-29T07:32:04.833699Z","iopub.execute_input":"2021-12-29T07:32:04.834018Z","iopub.status.idle":"2021-12-29T07:37:13.891572Z","shell.execute_reply.started":"2021-12-29T07:32:04.833984Z","shell.execute_reply":"2021-12-29T07:37:13.890603Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"Initializing ChatBot ...\nType \"bye\" or \"quit\" or \"exit\" to end chat\n\nEnter your topic of interest when prompted.         \nChaBot will access Wikipedia, prepare itself to         \nrespond to your queries on that topic. \n\nChatBot will respond with short info.         \nIf you input \"more\", it will give you detailed info         \nYou can also jump to next query\n--------------------------------------------------\nChatBot >>  Hello, Great day! Please give me a topic of your interest. \n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"User    >>  Canada\n"},{"name":"stdout","text":"ChatBot >>  Topic is \"Wikipedia: Canada\". Let's chat!\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"User    >>  what is the capital of canada?\n"},{"name":"stdout","text":"ChatBot >> Canada's capital is Ottawa , and its three largest metropolitan areas are Toronto , Montreal , and Vancouver .\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"User    >>  Are there islands in Canada?\n"},{"name":"stdout","text":"ChatBot >> St. John's Island (now Prince Edward Island ) became a separate colony in 1769.\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"User    >>  What is Canada's currency?\n"},{"name":"stdout","text":"ChatBot >> The Bank of Canada is the sole authority authorized to issue currency in the form of Canadian bank notes .\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"User    >>  About Canada's industries?\n"},{"name":"stdout","text":"ChatBot >> The Canadian economy boomed during the war as its industries manufactured military materiel for Canada, Britain, China , and the Soviet Union .\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"User    >>  Most spoken languages?\n"},{"name":"stdout","text":"ChatBot >> Manitoba, Ontario, and Quebec allow for both English and French to be spoken in the provincial legislatures, and laws are enacted in both languages.\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"User    >>  who is the first prime minister of Canada?\n"},{"name":"stdout","text":"ChatBot >> Its nine members are appointed by the governor general on the advice of the prime minister and minister of justice .\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"User    >>  more\n"},{"name":"stdout","text":"ChatBot >> Canada's judiciary plays an important role in interpreting laws and has the power to strike down Acts of Parliament that violate the constitution. The Supreme Court of Canada is the highest court and final arbiter and has been led since December 18, 2017, by Richard Wagner , the chief justice of Canada . Its nine members are appointed by the governor general on the advice of the prime minister and minister of justice . All judges at the superior and appellate levels are appointed after consultation with non-governmental legal bodies. The federal Cabinet also appoints justices to superior courts in the provincial and territorial jurisdictions. \n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"User    >>  water bodies\n"},{"name":"stdout","text":"ChatBot >> By total area (including its waters), Canada is the second-largest country in the world, after Russia .\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"User    >>  about embassies and high commissions of other countries?\n"},{"name":"stdout","text":"ChatBot >> Average winter and summer high temperatures across Canada vary from region to region.\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"User    >>  bye\n"},{"name":"stdout","text":"ChatBot >>  See you soon! Bye!\n\nQuitting ChatBot ...\n","output_type":"stream"}]}]}